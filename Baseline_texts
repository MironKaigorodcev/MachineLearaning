{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM2Eec0PR7zmy/vpVvjTojx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Baseline**"],"metadata":{"id":"7kKSsZSB6-1r"}},{"cell_type":"markdown","source":["Для первичной обработки текста используем **nltk**,\n","а в качестве baseline используем **логистическую регрессию**"],"metadata":{"id":"gh-cD0GN7Nbw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n2b2faAGacmk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740085647366,"user_tz":-180,"elapsed":7988,"user":{"displayName":"Мирон Кайгородцев","userId":"01513473299223894044"}},"outputId":"052b1c6a-5f42-4290-98d0-e33cdc766944"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["0.6829971181556196\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.pipeline import Pipeline\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import string\n","import nltk\n","\n","# Загрузка данных\n","df = pd.read_csv('train_texts.csv')\n","\n","# Присваеваем авторам номер (аметку класса)\n","label_encoder = LabelEncoder()\n","label_encoder.fit(df['author'])\n","df['author'] = label_encoder.transform(df['author'])\n","\n","#разбиваем данные на тренировочную и тествоую выборки\n","train_data, test_data, train_labels, test_labels = train_test_split(df['text'],df['author'], test_size=0.2)\n","\n","# Предобработка текста\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","stop_words = set(stopwords.words('russian'))\n","\n","def preprocess_text(text):\n","    text = text.lower()  # Приведение к нижнему регистру\n","    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))  # Удаление пунктуации и цифр\n","    tokens = word_tokenize(text, language='russian')  # Токенизация\n","    tokens = [word for word in tokens if word not in stop_words]  # Удаление стоп-слов\n","    return ' '.join(tokens)\n","\n","train_data = train_data.apply(preprocess_text)\n","test_data = test_data.apply(preprocess_text)\n","\n","# Векторизация текста\n","vectorizer = TfidfVectorizer(max_features=50000)\n","X_train = vectorizer.fit_transform(train_data)\n","y_train = train_labels\n","\n","# Обучение модели\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Предсказание на тестовых данных\n","X_test = vectorizer.transform(test_data)\n","predictions = model.predict(X_test)\n","print(accuracy_score(test_labels,predictions))\n","#test_data['author'] = predictions\n","#test_data[['id', 'author']].to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","source":["Пробуем с той же предобработкой обучить более сложную модель - одну из модификаций **градиентного бустинга**"],"metadata":{"id":"HypMkGds7mLH"}},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","XBC = XGBClassifier()\n","XBC.fit(X_train,y_train)\n","predictions1 = XBC.predict(X_test)\n","print(accuracy_score(test_labels,predictions1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2S8mT-fu5zup","executionInfo":{"status":"ok","timestamp":1740082826577,"user_tz":-180,"elapsed":49769,"user":{"displayName":"Мирон Кайгородцев","userId":"01513473299223894044"}},"outputId":"7598cf13-31e0-4ef9-b98d-29ae908dffcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.723342939481268\n"]}]},{"cell_type":"markdown","source":["# **FastText**\n"],"metadata":{"id":"d3yvhq7F8MaX"}},{"cell_type":"markdown","source":["**FastText** — это мощная библиотека для работы с текстовыми данными, разработанная Facebook AI Research. Она особенно полезна для задач классификации текста, так как учитывает морфологию слов (например, суффиксы и префиксы), что важно для языков с богатой морфологией, таких как русский."],"metadata":{"id":"O7F0Nc8F8S94"}},{"cell_type":"markdown","source":["FastText V2"],"metadata":{"id":"lZSWHj8VFVG4"}},{"cell_type":"code","source":["import keras\n","import keras.backend as K\n","from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","\n","from collections import defaultdict"],"metadata":{"id":"T3gpGYKKFXUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.random.seed(7)"],"metadata":{"id":"WwOL1QunFZDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["counter = {name : defaultdict(int) for name in set(df['author'])}\n","for (text, author) in zip(df['text'], df['author']):\n","    text = text.replace(' ', '')\n","    for c in text:\n","        counter[author][c] += 1\n","\n","chars = set()\n","for v in counter.values():\n","    chars |= v.keys()\n","\n","names = [author for author in counter.keys()]\n","\n","print('c ', end='')\n","for n in names:\n","    print(n, end='   ')\n","print()\n","for c in chars:\n","    print(c, end=' ')\n","    for n in names:\n","        print(counter[n][c], end=' ')\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"cy740I5dFwMi","executionInfo":{"status":"ok","timestamp":1740085667048,"user_tz":-180,"elapsed":482,"user":{"displayName":"Мирон Кайгородцев","userId":"01513473299223894044"}},"outputId":"27b52e69-9708-4bcf-efa6-0bb500d1d27f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["c 0   1   2   3   4   5   6   7   \n","9 53 6 6 4 4 94 11 3 \n","- 4204 2253 1626 959 829 3273 2650 565 \n","! 732 360 826 241 400 288 292 154 \n","« 1048 170 349 158 403 818 257 25 \n","б 11198 4113 4475 3037 2919 6663 4484 909 \n","Ė 2 0 0 0 0 0 0 0 \n","н 43078 15167 15768 11270 10242 26548 16978 3774 \n","r 48 0 11 12 7 25 7 0 \n","№ 57 3 0 0 1 0 1 0 \n","щ 2276 753 833 591 499 1433 1146 179 \n","Ы 3 0 0 1 0 29 38 0 \n","; 116 8 206 266 195 71 36 33 \n","S 7 0 1 1 0 8 2 0 \n","Г 618 307 177 84 255 283 183 55 \n","ч 10141 3745 4031 2996 2821 6296 4079 798 \n","“ 14 1 0 7 8 1 1 1 \n","Э 370 125 87 35 60 388 168 24 \n","ê 0 0 0 1 0 0 0 0 \n","c 36 1 13 22 6 23 3 0 \n","â 0 0 0 1 0 0 0 0 \n","3 39 1 14 7 25 19 6 0 \n",". 10089 4316 3329 1745 2058 6225 4245 969 \n","8 68 8 46 25 38 49 7 0 \n","F 4 0 2 0 0 4 0 0 \n","f 14 0 0 4 3 1 3 0 \n","ó 22 0 1 0 0 0 1 0 \n","ф 1243 432 301 209 152 680 595 138 \n","/ 1 0 0 1 0 1 18 0 \n","Н 1562 652 600 298 305 953 792 145 \n","´ 0 0 0 0 0 1 0 0 \n","O 4 0 1 1 1 3 0 0 \n","Y 1 0 0 0 0 0 0 0 \n","ь 12471 4708 5273 3367 3155 7917 5331 1174 \n","д 19406 7287 7999 5418 5122 12542 7743 1688 \n","u 46 0 8 21 9 3 5 0 \n","п 17835 6531 6357 4140 3957 10805 7110 1612 \n","й 8801 2793 3013 1879 2069 4855 3054 742 \n","Ь 2 0 0 1 0 17 40 0 \n","л 32197 13082 11732 7651 6959 20618 13107 3200 \n","P 3 0 1 1 0 7 8 0 \n","у 19411 7271 7717 4808 4753 11397 7355 1699 \n","э 1362 510 519 421 339 1508 867 154 \n","J 2 0 1 1 2 1 0 0 \n","‑ 0 0 0 0 0 1 0 0 \n","ô 0 0 1 0 0 0 0 0 \n","Й 17 2 0 0 0 65 17 3 \n","~ 4 0 0 0 0 0 0 0 \n","Ж 113 64 45 10 11 57 44 11 \n","K 3 0 0 0 0 5 0 0 \n","т 39892 15219 15681 10687 10156 26095 16402 3547 \n","́ 15 0 3 1 1 0 0 1 \n","x 3 0 3 0 0 0 0 0 \n",", 14854 5315 6837 4716 4185 9468 5957 1253 \n","м 19606 7192 7907 5725 5221 13406 8416 1963 \n","é 5 0 1 1 3 0 0 0 \n","\n"," 3290 1905 1209 445 653 2034 1851 405 \n","2 97 5 23 7 20 49 17 0 \n","U 0 0 0 0 0 4 0 0 \n","Ю 22 6 13 1 3 16 15 10 \n","7 56 1 18 8 11 39 3 0 \n","* 4 0 2 0 8 0 0 0 \n","Д 660 220 344 167 203 813 414 52 \n","Б 635 222 158 75 180 454 220 40 \n","( 375 32 193 48 90 220 54 0 \n","ц 3114 897 1054 668 637 1467 1040 273 \n","в 29080 9705 11077 7802 7600 16677 10619 2576 \n","М 806 354 376 147 142 685 424 78 \n","” 8 0 0 1 6 0 1 0 \n","ъ 215 58 70 49 44 99 37 8 \n","Ъ 0 0 0 0 0 4 0 0 \n",") 392 32 203 54 91 220 54 0 \n","m 29 0 26 36 9 4 2 0 \n","n 79 0 24 37 7 24 9 0 \n","M 8 0 1 2 5 2 2 0 \n","X 26 10 0 6 25 9 0 0 \n","s 63 0 17 28 12 15 2 0 \n","E 0 0 0 0 2 4 0 0 \n","6 61 3 13 4 9 31 6 1 \n","Л 404 120 136 37 47 304 187 29 \n","t 68 0 11 33 6 20 9 0 \n","Х 189 52 61 22 48 227 149 27 \n","П 1695 604 564 294 290 845 567 120 \n","к 23784 9375 8765 5918 6521 14233 9428 1988 \n","ш 5592 2367 2334 1467 1388 3446 2287 538 \n","î 1 0 0 0 0 0 0 0 \n","Ц 87 17 7 9 0 22 18 0 \n","k 18 0 0 1 0 3 0 0 \n","‘ 0 0 0 0 1 0 0 0 \n","Ш 117 36 38 13 16 72 61 28 \n","Я 452 267 247 116 96 468 207 44 \n","Ф 231 27 33 86 84 166 62 39 \n","„ 6 1 0 6 2 1 0 1 \n","á 10 0 0 0 4 0 0 0 \n","' 4 0 0 0 0 2 0 0 \n","ё 324 97 93 122 63 2 257 1 \n","D 0 0 0 3 1 7 0 0 \n","\" 0 0 0 0 2 0 0 0 \n","1 216 13 56 26 58 116 18 4 \n","4 49 7 9 4 18 41 10 0 \n","a 65 0 30 38 16 12 7 0 \n","‐ 0 0 0 0 0 1 0 0 \n","C 1 0 2 2 6 12 1 0 \n","I 68 6 1 24 35 15 1 4 \n","Q 0 0 0 0 0 0 2 0 \n","г 11313 3821 4817 3006 3257 7139 4599 1036 \n","0 90 3 31 10 16 58 12 0 \n","p 24 0 10 4 4 4 2 0 \n","… 286 119 779 95 171 384 327 75 \n","Т 878 341 328 166 185 671 609 74 \n","{ 0 0 0 0 0 0 3 0 \n","р 31394 10809 10755 7255 7122 18849 12046 2859 \n","Ч 351 110 329 86 140 278 184 25 \n","g 16 0 4 5 0 7 3 1 \n","А 837 707 303 146 284 436 418 53 \n","О 1038 492 466 204 243 912 763 145 \n","h 29 0 4 14 1 7 1 0 \n","= 2 0 0 0 0 0 0 0 \n","+ 1 0 0 0 0 0 1 0 \n","j 4 0 0 2 0 0 0 0 \n","о 75320 26058 28071 19394 18741 45427 30017 6447 \n","i 102 0 19 29 10 15 7 0 \n","H 3 0 1 0 11 0 0 0 \n","& 0 0 6 0 0 0 2 0 \n","— 1 0 0 1 0 0 0 2 \n","В 1468 627 643 271 334 892 756 139 \n","V 13 1 0 9 11 4 0 1 \n","х 5823 2091 2481 1518 1558 3732 2373 562 \n","з 11070 4262 4175 2775 2629 6805 4478 1120 \n","И 929 383 306 170 223 555 469 44 \n","G 1 0 0 0 0 0 1 1 \n","L 2 0 2 0 0 8 0 0 \n","С 1369 593 499 226 266 799 643 81 \n","T 2 0 0 0 0 6 1 0 \n","и 45364 16708 17063 11907 11514 28091 17744 3985 \n","® 1 0 0 0 0 0 0 0 \n","N 2 0 3 2 0 5 1 0 \n","½ 0 0 1 0 0 0 0 0 \n","o 83 0 24 36 17 28 10 2 \n","d 43 0 6 10 6 7 2 0 \n","? 824 497 468 187 245 557 422 81 \n","y 11 0 0 2 1 4 1 0 \n","З 428 192 127 45 71 202 151 23 \n","v 19 0 3 3 2 2 0 0 \n","q 2 0 0 4 0 2 0 0 \n","ю 4589 1359 1879 1162 1055 2692 1668 316 \n",": 910 212 253 188 264 395 192 73 \n","» 1033 171 350 158 400 816 256 25 \n","– 773 342 211 132 192 568 262 94 \n","b 21 0 7 10 0 4 2 0 \n","A 4 0 2 0 4 9 3 0 \n","а 53221 22040 21171 13251 12636 33745 20758 4750 \n","Ё 1 0 0 0 0 0 0 0 \n","e 116 0 37 82 23 43 11 0 \n","Е 336 130 192 70 67 357 257 22 \n","W 3 0 1 0 0 2 0 0 \n","ы 12719 4966 4677 3056 3104 7778 5183 1305 \n","с 36977 13028 12934 9477 8633 21543 13872 3173 \n","я 13479 4597 5846 3683 3250 8476 5278 1173 \n","ж 6397 2407 2922 2027 1704 4318 2690 581 \n","R 5 0 0 1 0 5 0 0 \n","’ 4 2 3 3 2 2 29 0 \n","У 336 193 118 40 64 296 156 27 \n","‹ 0 0 0 1 18 0 0 0 \n","Р 604 159 103 88 110 395 183 30 \n","Щ 3 3 2 0 2 4 12 1 \n","е 56108 20617 22434 15566 14593 34943 21872 5211 \n","› 0 0 0 1 17 0 0 0 \n","} 0 0 0 0 0 0 3 0 \n","l 51 0 14 33 6 10 4 0 \n","w 12 0 3 0 0 3 0 0 \n","B 1 0 1 6 9 2 4 0 \n","5 53 1 12 1 12 30 7 0 \n","z 1 0 9 0 1 0 1 0 \n","К 1061 498 381 134 178 699 430 164 \n"]}]},{"cell_type":"markdown","source":["# **Preprocessing**\n","\n","My preproceeings are\n","\n","- Separate punctuation from words\n","- Remove lower frequency words ( <= 2)\n","- Cut a longer document which contains `256` words"],"metadata":{"id":"i5KmFHICGH25"}},{"cell_type":"code","source":["def preprocess(text):\n","    text = text.replace(\"' \", \" ' \")\n","    signs = set(',.:;\"?!')\n","    prods = set(text) & signs\n","    if not prods:\n","        return text\n","\n","    for sign in prods:\n","        text = text.replace(sign, ' {} '.format(sign) )\n","    return text"],"metadata":{"id":"Cqb54-0_F8up"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_docs(df, n_gram_max=3):\n","    def add_ngram(q, n_gram_max):\n","            ngrams = []\n","            for n in range(2, n_gram_max+1):\n","                for w_index in range(len(q)-n+1):\n","                    ngrams.append('--'.join(q[w_index:w_index+n]))\n","            return q + ngrams\n","\n","    docs = []\n","    for doc in df['text']:\n","        doc = preprocess(doc).split()\n","        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n","\n","    return docs"],"metadata":{"id":"Z3GAA2shGO-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_count = 2\n","\n","docs = create_docs(df)\n","tokenizer = Tokenizer(lower=False, filters='')\n","tokenizer.fit_on_texts(docs)\n","num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n","\n","tokenizer = Tokenizer(num_words=num_words, lower=False, filters='')\n","tokenizer.fit_on_texts(docs)\n","docs = tokenizer.texts_to_sequences(docs)\n","\n","maxlen = 256\n","\n","docs = pad_sequences(sequences=docs, maxlen=maxlen)"],"metadata":{"id":"I8rTkp_4GTsh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Model: FastText by Keras**\n","\n","FastText is very fast and strong baseline algorithm for text classification based on Continuous Bag-of-Words model a.k.a Word2vec.\n","\n","FastText contains only three layers:\n","\n","1. Embeddings layer: Input words (and word n-grams) are all words in a sentence/document\n","2. Mean/AveragePooling Layer: Taking average vector of Embedding vectors\n","3. Softmax layer\n","\n","There are some implementations of FastText:\n","\n","- Original library provided by Facebook AI research: https://github.com/facebookresearch/fastText\n","- Keras: https://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py\n","- Gensim: https://radimrehurek.com/gensim/models/wrappers/fasttext.html\n","\n","Original Paper: https://arxiv.org/abs/1607.01759 : More detail information about fastText classification model"],"metadata":{"id":"M56xAGfeGdBe"}},{"cell_type":"markdown","source":["# My FastText parameters are:\n","\n","- The dimension of word vector is 20\n","- Optimizer is `Adam`\n","- Inputs are words and word bi-grams\n","  - you can change this parameter by passing the max n-gram size to argument of `create_docs` function.\n"],"metadata":{"id":"NRedtgGKGjSV"}},{"cell_type":"markdown","source":[],"metadata":{"id":"xBoGXEr1GiLc"}},{"cell_type":"code","source":["input_dim = np.max(docs) + 1\n","embedding_dims = 20"],"metadata":{"collapsed":true,"id":"i9zsoxlUGYTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model(embedding_dims=20, optimizer='adam'):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n","    model.add(GlobalAveragePooling1D())\n","    model.add(Dense(8, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=optimizer,\n","                  metrics=['accuracy'])\n","    return model"],"metadata":{"id":"QSVxPVl5GqOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CzFHZZ1pEcu0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 25\n","label_encoder = LabelEncoder()\n","label_encoder.fit(df['author'])\n","y = np.array(label_encoder.transform(df['author']))\n","y = to_categorical(y)\n","x_train, x_test, y_train, y_test = train_test_split(docs,y, test_size=0.2)\n","model = create_model()\n","hist = model.fit(x_train, y_train,\n","                 batch_size=16,\n","                 validation_data=(x_test, y_test),\n","                 epochs=epochs,\n","                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2GJnY0jaGuwd","executionInfo":{"status":"ok","timestamp":1740085860004,"user_tz":-180,"elapsed":63347,"user":{"displayName":"Мирон Кайгородцев","userId":"01513473299223894044"}},"outputId":"46a5ae35-c41e-4bf2-ecee-ce8590c23643"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.2470 - loss: 2.0458 - val_accuracy: 0.3228 - val_loss: 1.9537\n","Epoch 2/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.2546 - loss: 1.9165 - val_accuracy: 0.3228 - val_loss: 1.8749\n","Epoch 3/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.2941 - loss: 1.8171 - val_accuracy: 0.3314 - val_loss: 1.8297\n","Epoch 4/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.3323 - loss: 1.7528 - val_accuracy: 0.3833 - val_loss: 1.7869\n","Epoch 5/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4034 - loss: 1.6665 - val_accuracy: 0.4092 - val_loss: 1.7436\n","Epoch 6/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4837 - loss: 1.6185 - val_accuracy: 0.4352 - val_loss: 1.6956\n","Epoch 7/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5679 - loss: 1.5206 - val_accuracy: 0.4755 - val_loss: 1.6457\n","Epoch 8/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6615 - loss: 1.4013 - val_accuracy: 0.5187 - val_loss: 1.5887\n","Epoch 9/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7129 - loss: 1.3168 - val_accuracy: 0.5648 - val_loss: 1.5306\n","Epoch 10/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7808 - loss: 1.2095 - val_accuracy: 0.6023 - val_loss: 1.4736\n","Epoch 11/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7953 - loss: 1.1206 - val_accuracy: 0.6225 - val_loss: 1.4137\n","Epoch 12/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8208 - loss: 1.0088 - val_accuracy: 0.6657 - val_loss: 1.3598\n","Epoch 13/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8474 - loss: 0.9012 - val_accuracy: 0.6888 - val_loss: 1.3034\n","Epoch 14/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8772 - loss: 0.7854 - val_accuracy: 0.6916 - val_loss: 1.2536\n","Epoch 15/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8828 - loss: 0.7329 - val_accuracy: 0.6974 - val_loss: 1.2065\n","Epoch 16/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9010 - loss: 0.6396 - val_accuracy: 0.7118 - val_loss: 1.1608\n","Epoch 17/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9150 - loss: 0.5721 - val_accuracy: 0.7349 - val_loss: 1.1209\n","Epoch 18/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9077 - loss: 0.5424 - val_accuracy: 0.7291 - val_loss: 1.0840\n","Epoch 19/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9329 - loss: 0.4610 - val_accuracy: 0.7493 - val_loss: 1.0505\n","Epoch 20/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9410 - loss: 0.4074 - val_accuracy: 0.7522 - val_loss: 1.0201\n","Epoch 21/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9480 - loss: 0.3639 - val_accuracy: 0.7579 - val_loss: 0.9907\n","Epoch 22/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9660 - loss: 0.3273 - val_accuracy: 0.7608 - val_loss: 0.9643\n","Epoch 23/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9691 - loss: 0.2909 - val_accuracy: 0.7637 - val_loss: 0.9394\n","Epoch 24/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.2613 - val_accuracy: 0.7666 - val_loss: 0.9175\n","Epoch 25/25\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9744 - loss: 0.2303 - val_accuracy: 0.7723 - val_loss: 0.8944\n"]}]},{"cell_type":"markdown","source":["# **2.1 Change Preprocessings**\n","\n","Next, I change some parameters and preprocessings to improve fastText model.\n","## **2.1.1 Do lower case**"],"metadata":{"id":"IM8K4x_xG3wA"}},{"cell_type":"code","source":["docs = create_docs(df)\n","tokenizer = Tokenizer(lower=True, filters='')\n","tokenizer.fit_on_texts(docs)\n","num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n","\n","tokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\n","tokenizer.fit_on_texts(docs)\n","docs = tokenizer.texts_to_sequences(docs)\n","\n","maxlen = 256\n","\n","docs = pad_sequences(sequences=docs, maxlen=maxlen)\n","\n","input_dim = np.max(docs) + 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"dGywAydoG5if","executionInfo":{"status":"ok","timestamp":1740086464261,"user_tz":-180,"elapsed":14084,"user":{"displayName":"Мирон Кайгородцев","userId":"01513473299223894044"}},"outputId":"1ba71f77-cb97-475e-9ef7-f507ae85e8da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["99317"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["qepochs = 40\n","x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n","\n","model = create_model()\n","hist = model.fit(x_train, y_train,\n","                 batch_size=16,\n","                 validation_data=(x_test, y_test),\n","                 epochs=epochs,\n","                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"WMEyloT8HBWW","executionInfo":{"status":"ok","timestamp":1740086029971,"user_tz":-180,"elapsed":97961,"user":{"displayName":"Мирон Кайгородцев","userId":"01513473299223894044"}},"outputId":"3678ee87-f1e2-499b-b93d-cdb724b2840a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.2488 - loss: 2.0504 - val_accuracy: 0.3285 - val_loss: 1.9588\n","Epoch 2/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.2676 - loss: 1.9320 - val_accuracy: 0.3256 - val_loss: 1.8700\n","Epoch 3/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.2782 - loss: 1.8464 - val_accuracy: 0.3487 - val_loss: 1.8136\n","Epoch 4/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.3501 - loss: 1.7530 - val_accuracy: 0.3919 - val_loss: 1.7651\n","Epoch 5/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4358 - loss: 1.6650 - val_accuracy: 0.4150 - val_loss: 1.7181\n","Epoch 6/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4949 - loss: 1.6007 - val_accuracy: 0.4611 - val_loss: 1.6671\n","Epoch 7/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5878 - loss: 1.5263 - val_accuracy: 0.5072 - val_loss: 1.6153\n","Epoch 8/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6879 - loss: 1.3677 - val_accuracy: 0.5562 - val_loss: 1.5585\n","Epoch 9/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7368 - loss: 1.2791 - val_accuracy: 0.5821 - val_loss: 1.5004\n","Epoch 10/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7923 - loss: 1.1614 - val_accuracy: 0.5850 - val_loss: 1.4446\n","Epoch 11/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8192 - loss: 1.0490 - val_accuracy: 0.6254 - val_loss: 1.3873\n","Epoch 12/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8438 - loss: 0.9666 - val_accuracy: 0.6513 - val_loss: 1.3336\n","Epoch 13/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8748 - loss: 0.8434 - val_accuracy: 0.6830 - val_loss: 1.2814\n","Epoch 14/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.8870 - loss: 0.7361 - val_accuracy: 0.7032 - val_loss: 1.2320\n","Epoch 15/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8757 - loss: 0.7009 - val_accuracy: 0.7089 - val_loss: 1.1872\n","Epoch 16/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9107 - loss: 0.5877 - val_accuracy: 0.7205 - val_loss: 1.1476\n","Epoch 17/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9199 - loss: 0.5510 - val_accuracy: 0.7233 - val_loss: 1.1086\n","Epoch 18/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9334 - loss: 0.4655 - val_accuracy: 0.7291 - val_loss: 1.0732\n","Epoch 19/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9457 - loss: 0.4270 - val_accuracy: 0.7406 - val_loss: 1.0427\n","Epoch 20/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9708 - loss: 0.3531 - val_accuracy: 0.7464 - val_loss: 1.0118\n","Epoch 21/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9685 - loss: 0.3270 - val_accuracy: 0.7550 - val_loss: 0.9841\n","Epoch 22/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9797 - loss: 0.2817 - val_accuracy: 0.7550 - val_loss: 0.9606\n","Epoch 23/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9691 - loss: 0.2740 - val_accuracy: 0.7550 - val_loss: 0.9382\n","Epoch 24/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9813 - loss: 0.2432 - val_accuracy: 0.7637 - val_loss: 0.9142\n","Epoch 25/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9801 - loss: 0.2267 - val_accuracy: 0.7666 - val_loss: 0.8969\n","Epoch 26/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9707 - loss: 0.2043 - val_accuracy: 0.7666 - val_loss: 0.8805\n","Epoch 27/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9759 - loss: 0.1852 - val_accuracy: 0.7695 - val_loss: 0.8623\n","Epoch 28/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9778 - loss: 0.1694 - val_accuracy: 0.7723 - val_loss: 0.8475\n","Epoch 29/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9802 - loss: 0.1463 - val_accuracy: 0.7752 - val_loss: 0.8327\n","Epoch 30/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9744 - loss: 0.1473 - val_accuracy: 0.7781 - val_loss: 0.8174\n","Epoch 31/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9734 - loss: 0.1304 - val_accuracy: 0.7839 - val_loss: 0.8045\n","Epoch 32/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9774 - loss: 0.1282 - val_accuracy: 0.7839 - val_loss: 0.7944\n","Epoch 33/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9789 - loss: 0.1046 - val_accuracy: 0.7896 - val_loss: 0.7855\n","Epoch 34/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9840 - loss: 0.0996 - val_accuracy: 0.7896 - val_loss: 0.7746\n","Epoch 35/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9781 - loss: 0.0974 - val_accuracy: 0.7925 - val_loss: 0.7651\n","Epoch 36/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9795 - loss: 0.0855 - val_accuracy: 0.7925 - val_loss: 0.7555\n","Epoch 37/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9769 - loss: 0.0937 - val_accuracy: 0.7925 - val_loss: 0.7483\n","Epoch 38/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9749 - loss: 0.0828 - val_accuracy: 0.7954 - val_loss: 0.7403\n","Epoch 39/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9728 - loss: 0.0839 - val_accuracy: 0.7954 - val_loss: 0.7335\n","Epoch 40/40\n","\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9803 - loss: 0.0798 - val_accuracy: 0.7954 - val_loss: 0.7258\n"]}]}]}